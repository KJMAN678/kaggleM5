{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考  \n",
    "### kaggle notebook lightGBM\n",
    "https://www.kaggle.com/girmdshinsei/for-japanese-beginner-with-wrmsse-in-lgbm?scriptVersionId=31044557\n",
    "\n",
    "### lightGBM 時系列\n",
    "https://qiita.com/ground0state/items/657861de619a4e4a30de\n",
    "\n",
    "### Feature Scalingはなぜ必要？ 標準化と正規化の使い分け\n",
    "https://qiita.com/ttskng/items/2a33c1ca925e4501e609\n",
    "\n",
    "### Quick start catboost\n",
    "https://catboost.ai/docs/concepts/python-quickstart.html\n",
    "\n",
    "### Pythonでcatboostを使ってみる\n",
    "#### (cat_featuresの使い方を調べた)\n",
    "https://qiita.com/shin_mura/items/3d9ce25a60bdd25a3333\n",
    "\n",
    "### LightGBMとOptunaを導入・動かしてみる\n",
    "https://kiseno-log.com/2019/11/05/lightgbm%E3%81%A8optuna%E3%82%92%E5%B0%8E%E5%85%A5%E3%83%BB%E5%8B%95%E3%81%8B%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ラベルエンコーダー\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "# lightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# CatBoost\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1セルでまとめて.head()、.tail()等を入力しても大丈夫になる\n",
    "from IPython.display import display\n",
    "\n",
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 誤差算定\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 二乗平均平方根誤差 (RMSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 決定係数\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# DataFrameの表示数を変更\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカル用\n",
    "path = os.getcwd() + \"/\"\n",
    "\n",
    "# kaggle Notebook用\n",
    "INPUT_DIR = '../input/m5-forecasting-accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calendar.csv -製品の販売日に関する情報が含まれています。\n",
    "sales_train_validation.csv -製品および店舗ごとの過去の毎日の販売台数データが​​含まれています [d_1 - d_1913]\n",
    "sample_submission.csv-提出の正しい形式。詳細については、「評価」タブを参照してください。\n",
    "sell_prices.csv -店舗および日付ごとに販売された製品の価格に関する情報が含まれています。\n",
    "\n",
    "sales_train_evaluation.csv-締め切りの1か月前に1回ご利用いただけます。売上高が含まれます[d_1 - d_1941]\n",
    "\n",
    "各行は含むidの連結であるitem_idとstore_idのいずれかである、validation（公共のランキングに対応する）、またはevaluation（プライベートランキングに対応します）。　　 F1-F28各行で販売されるアイテムの28予測日（）を予測しています。　　 以下のためのvalidation行、これに相当するd_1914 - d_1941、とのためevaluationの行、これに相当しますd_1942 - d_1969。　　\n",
    "\n",
    "validation d_1914 - d_1941の単価と量を予測する。１か月前に１回公開される。 evaluation d_1942-d_1969の単価と量を予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作成データの読込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stv_melt = pd.read_pickle(path + \"melt_stv.pkl\")\n",
    "except FileNotFoundError:\n",
    "    1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_train_validation.csv\n",
    "try:\n",
    "    stv = pd.read_csv(path + \"sales_train_validation.csv\") # ローカル用\n",
    "except FileNotFoundError:\n",
    "    stv = pd.read_csv(f\"{INPUT_DIR}/sales_train_validation.csv\") # kaggle用\n",
    "\n",
    "    \n",
    "# calendar.csv\n",
    "try:\n",
    "    cal = pd.read_csv(path + \"calendar.csv\") # ローカル用\n",
    "except FileNotFoundError:\n",
    "    cal = pd.read_csv(f\"{INPUT_DIR}/calendar.csv\") # kaggle用\n",
    "\n",
    "    \n",
    "# sell_prices.csv\n",
    "try:\n",
    "    price = pd.read_csv(path + \"sell_prices.csv\") # ローカル用\n",
    "except FileNotFoundError:\n",
    "    price = pd.read_csv(f\"{INPUT_DIR}/sell_prices.csv\") # kaggle用\n",
    "\n",
    "    \n",
    "# sample_submission.csv\n",
    "try:\n",
    "    ss = pd.read_csv(path + \"sample_submission.csv\") # ローカル用\n",
    "except FileNotFoundError:\n",
    "    ss = pd.read_csv(f\"{INPUT_DIR}/sample_submission.csv\") # kaggle用\n",
    "\n",
    "stv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ロースペックマシン限定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv = pd.read_csv(path + \"sales_train_validation.csv\",\n",
    "                               skiprows=lambda x: x not in range(0,1001))\n",
    "\n",
    "cal = pd.read_csv(path + \"calendar.csv\",\n",
    "                               skiprows=lambda x: x not in range(0,3001))\n",
    "\n",
    "price = pd.read_csv(path + \"sell_prices.csv\",\n",
    "                               skiprows=lambda x: x not in range(0,3001))\n",
    "\n",
    "ss = pd.read_csv(path + \"sample_submission.csv\",\n",
    "                               skiprows=lambda x: x not in range(0,1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stv.head())\n",
    "display(stv.tail())\n",
    "display(stv.dtypes)\n",
    "display(cal.head())\n",
    "display(cal.tail())\n",
    "display(cal.dtypes)\n",
    "display(cal.max())\n",
    "display(price.head())\n",
    "display(price.tail())\n",
    "display(price.dtypes)\n",
    "display(price.max())\n",
    "display(price.shape)\n",
    "display(ss.head())\n",
    "display(ss.tail())\n",
    "display(ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_1913 = [f\"d_{i}\" for i in range(1, 1914)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt =  pd.melt(stv, id_vars=['id','store_id','item_id'],\n",
    "           value_vars=day1_1913,\n",
    "           var_name = \"d\", value_name = \"vol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del day1_1913\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = stv[[\"id\",\"item_id\",\"store_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_val = ss[0:30490]\n",
    "ss_val.columns = [\"id\"] + [f\"d_{d}\" for d in range(1914, 1942)]\n",
    "\n",
    "ss_eva = ss[30490:60980]\n",
    "ss_eva.columns = [\"id\"] + [f\"d_{d}\" for d in range(1942, 1970)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_eva['id'] = ss_eva['id'].str.replace('_evaluation','_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_val = pd.merge(ss_val, product, how = 'left', left_on = ['id'], right_on = ['id'])\n",
    "ss_eva = pd.merge(ss_eva, product, how = 'left', left_on = ['id'], right_on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ss_val.head(3))\n",
    "display(ss_val.tail(3))\n",
    "display(ss_val.shape)\n",
    "display(ss_eva.head(3))\n",
    "display(ss_eva.tail(3))\n",
    "display(ss_eva.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_1914_1941 = [f\"d_{i}\" for i in range(1914, 1942)]\n",
    "eva_1942_1969 = [f\"d_{i}\" for i in range(1942, 1970)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_melt =  pd.melt(ss_val, id_vars=['id','store_id', \"item_id\"],\n",
    "           value_vars=val_1914_1941,\n",
    "           var_name = \"d\", value_name = \"vol\")\n",
    "eva_melt =  pd.melt(ss_eva, id_vars=['id','store_id', \"item_id\"],\n",
    "           value_vars=eva_1942_1969,\n",
    "           var_name = \"d\", value_name = \"vol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt = pd.concat([stv_melt, val_melt, eva_melt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stv_melt.head(3))\n",
    "display(stv_melt.tail(3))\n",
    "display(stv_melt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ss, ss_val, ss_eva, val_1914_1941, eva_1942_1969, val_melt, eva_melt, product\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = cal[[\"date\",\"wm_yr_wk\",\"d\",\"event_name_1\",\"event_type_1\",\"event_name_2\",\"event_type_2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt = pd.merge(stv_melt, cal, how = 'left', left_on = ['d'], right_on = ['d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cal\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stv_melt.head())\n",
    "display(stv_melt.tail())\n",
    "display(stv_melt.dtypes)\n",
    "display(stv_melt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt = stv_melt.merge(price, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del price\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stv_melt.head())\n",
    "display(stv_melt.tail())\n",
    "display(stv_melt.dtypes)\n",
    "display(stv_melt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt[\"date2\"] = pd.to_datetime(stv_melt[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt[\"year\"] = stv_melt[\"date2\"].dt.year\n",
    "stv_melt[\"month\"] = stv_melt[\"date2\"].dt.month\n",
    "stv_melt[\"week\"] = stv_melt[\"date2\"].dt.week\n",
    "stv_melt[\"day\"] = stv_melt[\"date2\"].dt.day\n",
    "stv_melt[\"dayofweek\"] = stv_melt[\"date2\"].dt.dayofweek\n",
    "\n",
    "stv_melt[\"year\"] = stv_melt[\"year\"].astype('int8')\n",
    "stv_melt[\"month\"] = stv_melt[\"month\"].astype('int8')\n",
    "stv_melt[\"week\"] = stv_melt[\"week\"].astype('int8')\n",
    "stv_melt[\"day\"] = stv_melt[\"day\"].astype('int8')\n",
    "stv_melt[\"dayofweek\"] = stv_melt[\"dayofweek\"].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt = stv_melt.drop(\"date2\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　ラグの作成\n",
    "for i in [7,30,90]:\n",
    "    stv_melt['shift%s'%i] = stv_melt[\"vol\"].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均値\n",
    "'''\n",
    "for i in [7,30,90]:\n",
    "    stv_melt['mean%s'%i] = stv_melt[\"vol\"].rolling(i).mean()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中央値\n",
    "'''\n",
    "for i in [7,30,90]:\n",
    "    stv_melt['median%s'%i] = stv_melt[\"vol\"].rolling(i).median()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最小値\n",
    "'''\n",
    "for i in [7,30,90]:\n",
    "    stv_melt['min%s'%i] = stv_melt[\"vol\"].rolling(i).min()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stv_melt.head(3))\n",
    "display(stv_melt.tail(3))\n",
    "display(stv_melt.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt[\"vol\"] = stv_melt[[\"vol\"]].astype('int16')\n",
    "stv_melt[\"wm_yr_wk\"] = stv_melt[ \"wm_yr_wk\"].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt[\"sell_price\"] = stv_melt[\"sell_price\"].astype('float16')\n",
    "stv_melt[\"shift7\"] = stv_melt[\"shift7\"].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_melt[\"shift30\"] = stv_melt[\"shift30\"].astype('float16')\n",
    "stv_melt[\"shift90\"] = stv_melt[\"shift90\"].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルエンコーダー\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "stv_melt[\"store_id\"] = lbl.fit_transform(stv_melt[\"store_id\"])\n",
    "stv_melt[\"item_id\"] = lbl.fit_transform(stv_melt[\"item_id\"])\n",
    "\n",
    "stv_melt[\"store_id\"] = stv_melt[\"store_id\"].astype('int8')\n",
    "stv_melt[\"item_id\"] = stv_melt[\"item_id\"].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event は欠損値があるので前処理\n",
    "stv_melt[\"event_name_1\"] = stv_melt[\"event_name_1\"].fillna(\"missing\", inplace=True)\n",
    "stv_melt[\"event_type_1\"] = stv_melt[\"event_type_1\"].fillna(\"missing\", inplace=True)\n",
    "stv_melt[\"event_name_2\"] = stv_melt[\"event_name_2\"].fillna(\"missing\", inplace=True)\n",
    "stv_melt[\"event_type_2\"] = stv_melt[\"event_type_2\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "stv_melt[\"event_name_1\"] = lbl.fit_transform(stv_melt[\"event_name_1\"])\n",
    "stv_melt[\"event_type_1\"] = lbl.fit_transform(stv_melt[\"event_type_1\"])\n",
    "stv_melt[\"event_name_2\"] = lbl.fit_transform(stv_melt[\"event_name_2\"])\n",
    "stv_melt[\"event_type_2\"] = lbl.fit_transform(stv_melt[\"event_type_2\"])\n",
    "\n",
    "stv_melt[\"event_name_1\"] = stv_melt[\"event_name_1\"].astype('int8')\n",
    "stv_melt[\"event_name_2\"] = stv_melt[\"event_name_2\"].astype('int8')\n",
    "stv_melt[\"event_type_1\"] = stv_melt[\"event_type_1\"].astype('int8')\n",
    "stv_melt[\"event_type_2\"] = stv_melt[\"event_type_2\"].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>d</th>\n",
       "      <th>vol</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>shift7</th>\n",
       "      <th>shift30</th>\n",
       "      <th>shift90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>-99</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>-98</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>-97</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  store_id  item_id    d  vol        date  \\\n",
       "0  HOBBIES_1_001_CA_1_validation         0      -99  d_1    0  2011-01-29   \n",
       "1  HOBBIES_1_002_CA_1_validation         0      -98  d_1    0  2011-01-29   \n",
       "2  HOBBIES_1_003_CA_1_validation         0      -97  d_1    0  2011-01-29   \n",
       "\n",
       "   wm_yr_wk  event_name_1  event_type_1  event_name_2  event_type_2  \\\n",
       "0     11101             0             0             0             0   \n",
       "1     11101             0             0             0             0   \n",
       "2     11101             0             0             0             0   \n",
       "\n",
       "   sell_price  year  month  week  day  dayofweek  shift7  shift30  shift90  \n",
       "0         NaN   -37      1     4   29          5     NaN      NaN      NaN  \n",
       "1         NaN   -37      1     4   29          5     NaN      NaN      NaN  \n",
       "2         NaN   -37      1     4   29          5     NaN      NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>d</th>\n",
       "      <th>vol</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>shift7</th>\n",
       "      <th>shift30</th>\n",
       "      <th>shift90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60034807</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>9</td>\n",
       "      <td>-102</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>-32</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60034808</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>9</td>\n",
       "      <td>-101</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>-32</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60034809</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>9</td>\n",
       "      <td>-100</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  store_id  item_id       d  vol  \\\n",
       "60034807  FOODS_3_825_WI_3_validation         9     -102  d_1969    0   \n",
       "60034808  FOODS_3_826_WI_3_validation         9     -101  d_1969    0   \n",
       "60034809  FOODS_3_827_WI_3_validation         9     -100  d_1969    0   \n",
       "\n",
       "                date  wm_yr_wk  event_name_1  event_type_1  event_name_2  \\\n",
       "60034807  2016-06-19     11621             0             0             0   \n",
       "60034808  2016-06-19     11621             0             0             0   \n",
       "60034809  2016-06-19     11621             0             0             0   \n",
       "\n",
       "          event_type_2  sell_price  year  month  week  day  dayofweek  shift7  \\\n",
       "60034807             0    3.980469   -32      6    24   19          6     0.0   \n",
       "60034808             0    1.280273   -32      6    24   19          6     0.0   \n",
       "60034809             0    1.000000   -32      6    24   19          6     0.0   \n",
       "\n",
       "          shift30  shift90  \n",
       "60034807      0.0      0.0  \n",
       "60034808      0.0      0.0  \n",
       "60034809      0.0      0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id               object\n",
       "store_id           int8\n",
       "item_id            int8\n",
       "d                object\n",
       "vol               int16\n",
       "date             object\n",
       "wm_yr_wk          int16\n",
       "event_name_1       int8\n",
       "event_type_1       int8\n",
       "event_name_2       int8\n",
       "event_type_2       int8\n",
       "sell_price      float16\n",
       "year               int8\n",
       "month              int8\n",
       "week               int8\n",
       "day                int8\n",
       "dayofweek          int8\n",
       "shift7          float16\n",
       "shift30         float16\n",
       "shift90         float16\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(stv_melt.head(3))\n",
    "display(stv_melt.tail(3))\n",
    "display(stv_melt.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習用データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = stv_melt[stv_melt['date'] <= '2016-03-27']\n",
    "y_train = x_train['vol']\n",
    "x_val   = stv_melt[(stv_melt['date'] > '2016-03-27') & (stv_melt['date'] <= '2016-04-24')]\n",
    "y_val   = x_val['vol']\n",
    "test    = stv_melt[(stv_melt['date'] > '2016-04-24')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test.head())\n",
    "display(test.tail())\n",
    "display(test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stv_melt\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost モデルの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_features = [\n",
    "    \"store_id\",\n",
    "    \"sell_price\",\n",
    "    \"event_name_1\",\n",
    "    \"event_type_1\",\n",
    "    \"event_name_2\",\n",
    "    \"event_type_2\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"week\",\n",
    "    \"day\",\n",
    "    \"dayofweek\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用のパラメータ\n",
    "xgb_params = {\n",
    "    # 二値分類問題\n",
    "    'objective': 'binary:logistic',\n",
    "    # 評価指標\n",
    "    'eval_metric': 'logloss',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = xgb.XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:35:03] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[23:35:13] src/objective/regression_obj.cu:101: label must be in [0,1] for logistic regression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0cff8e1e6eec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxgb_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\conda ML\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda ML\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda ML\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda ML\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda ML\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [23:35:13] src/objective/regression_obj.cu:101: label must be in [0,1] for logistic regression"
     ]
    }
   ],
   "source": [
    "model3.fit(x_train[xgb_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証用データが各クラスに分類される確率を計算する\n",
    "y_pred3 = model3.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = test\n",
    "test3['vol'] = y_preds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y_pred3.head())\n",
    "display(y_pred3.tail())\n",
    "display(y_pred3.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### しきい値 0.5 で 0, 1 に丸める\n",
    "y_pred = np.where(y_pred_proba > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightGBM モデルの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"store_id\",\n",
    "    \"item_id\",\n",
    "    \"sell_price\",\n",
    "    \"shift7\",\n",
    "    \"shift30\",\n",
    "    \"shift90\",\n",
    "    \"event_name_1\",\n",
    "    \"event_type_1\",\n",
    "    \"event_name_2\",\n",
    "    \"event_type_2\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"week\",\n",
    "    \"day\",\n",
    "    \"dayofweek\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'rmse',\n",
    "    'objective': 'regression',\n",
    "    'n_jobs': -1,\n",
    "    'seed': 236,\n",
    "    'learning_rate': 0.1,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 10, \n",
    "    'colsample_bytree': 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = lgb.Dataset(x_train[features], y_train)\n",
    "val_set = lgb.Dataset(x_val[features], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.train(params, train_set, num_boost_round = 2500, early_stopping_rounds = 50, valid_sets = [train_set, val_set], verbose_eval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model_lgb.predict(x_val[features])\n",
    "val_score = np.sqrt(metrics.mean_squared_error(val_pred, y_val))\n",
    "print(f'Our val rmse score は {val_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lgb.predict(test[features])\n",
    "test['vol'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test[['id', 'date', 'vol']]\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'vol').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(predictions.head())\n",
    "display(predictions.tail())\n",
    "display(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features, params, x_train, y_train, x_val, y_val, test, model_lgb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_val = predictions.iloc[:,:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_eva = pd.concat([predictions.iloc[:,0],predictions.iloc[:,29:57]], axis=1)\n",
    "pre_eva['id'] = pre_eva['id'].str.replace('_validation', '_evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del predictions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pre_val.head())\n",
    "display(pre_val.tail())\n",
    "display(pre_val.shape)\n",
    "\n",
    "display(pre_eva.head())\n",
    "display(pre_eva.tail())\n",
    "display(pre_eva.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_val.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "pre_eva.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboostの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Pool\n",
    "train_pool = Pool(x_train[features], \n",
    "                  y_train)\n",
    "\n",
    "test_pool = Pool(test[features]) \n",
    "\n",
    "# specify the training parameters\n",
    "model2 = CatBoostRegressor(iterations=2000,\n",
    "                          depth=5,\n",
    "                          learning_rate=0.05,\n",
    "                          loss_function='RMSE')\n",
    "#train the model\n",
    "model2.fit(train_pool)\n",
    "# make the prediction using the resulting model\n",
    "preds2 = model2.predict(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test\n",
    "test2['vol'] = preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = test2[['id', 'date', 'vol']]\n",
    "predictions2 = pd.pivot(predictions2, index = 'id', columns = 'date', values = 'vol').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_val2 = predictions2.iloc[:,:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_eva2 = pd.concat([predictions2.iloc[:,0],predictions2.iloc[:,29:57]], axis=1)\n",
    "pre_eva2['id'] = pre_eva2['id'].str.replace('_validation', '_evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_val2.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "pre_eva2.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pre_val2.head())\n",
    "display(pre_val2.tail())\n",
    "display(pre_val2.shape)\n",
    "\n",
    "display(pre_eva2.head())\n",
    "display(pre_eva2.tail())\n",
    "display(pre_eva2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤差率の検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta = pd.read_csv(path + \"sales_train_evaluation.csv\")\n",
    "sta = sta[[\"d_1914\", \"d_1915\",\"d_1916\",\"d_1917\",\"d_1918\",\"d_1919\",\"d_1920\",\"d_1921\",\"d_1922\",\"d_1923\",\"d_1924\",\"d_1925\",\"d_1926\",\"d_1927\",\"d_1928\",\"d_1929\",\"d_1930\",\"d_1931\",\"d_1932\",\"d_1933\",\"d_1934\",\"d_1935\",\"d_1936\",\"d_1937\",\"d_1938\",\"d_1939\",\"d_1940\",\"d_1941\"]]\n",
    "sta.columns = [\"F1\", \"F2\",\"F3\",\"F4\",\"F5\",\"F6\",\"F7\",\"F8\",\"F9\",\"F10\",\"F11\",\"F12\",\"F13\",\"F14\",\"F15\",\"F16\",\"F17\",\"F18\",\"F19\",\"F20\",\"F21\",\"F22\",\"F23\",\"F24\",\"F25\",\"F26\",\"F27\",\"F28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"F1\", \"F2\",\"F3\",\"F4\",\"F5\",\"F6\",\"F7\",\"F8\",\"F9\",\"F10\",\"F11\",\"F12\",\"F13\",\"F14\",\"F15\",\"F16\",\"F17\",\"F18\",\"F19\",\"F20\",\"F21\",\"F22\",\"F23\",\"F24\",\"F25\",\"F26\",\"F27\",\"F28\"]:\n",
    "    sta[i] = sta[i].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_val_temp = pre_val.drop(\"id\",axis=1)\n",
    "pre_val2_temp = pre_val2.drop(\"id\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sta.head())\n",
    "display(sta.tail())\n",
    "display(sta.dtypes)\n",
    "display(pre_val_temp.head())\n",
    "display(pre_val_temp.tail())\n",
    "display(pre_val_temp.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d_1914_1941 の誤差率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二乗平均平方根誤差 (RMSE)\n",
    "display(np.sqrt(mean_squared_error(sta, pre_val_temp)))\n",
    "display(np.sqrt(mean_squared_error(sta, pre_val2_temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均絶対誤差 (MAE)\n",
    "display(mean_absolute_error(sta, pre_val_temp))\n",
    "display(mean_absolute_error(sta, pre_val2_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定係数\n",
    "# モデルの当てはまりの良さを示す指標で、最も当てはまりの良い場合、1.0 となります\n",
    "display(r2_score(sta, pre_val_temp))\n",
    "display(r2_score(sta, pre_val2_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "del sta, pre_val_temp,pre_val2_temp, i\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ統合 csv保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_uni = pd.concat([pre_val, pre_eva], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_uni2 = pd.concat([pre_val2, pre_eva2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pre_val, pre_eva, pre_val2, pre_eva2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_uni_am = pre_uni.set_index('id') * 0.4 + pre_uni2.set_index('id') * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_uni_am = pre_uni_am.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pre_uni, pre_uni2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pre_uni_am.head())\n",
    "display(pre_uni_am.tail())\n",
    "display(pre_uni_am.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_uni_am.to_csv('submission_uni.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pre_uni_am\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
